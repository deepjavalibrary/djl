import java.util.zip.GZIPInputStream

group "ai.djl.huggingface"

dependencies {
    api project(":api")

    testImplementation project(":engines:pytorch:pytorch-engine")
    testImplementation project(":testing")
    testImplementation "org.slf4j:slf4j-simple:${slf4j_version}"
}

compileJava.dependsOn(processResources)

processResources {
    inputs.properties "projectVersion": djl_version, "tokenizersVersion": tokenizers_version, "version": version
    def baseResourcePath = "${project.projectDir}/build/resources/main"
    outputs.dirs file("${baseResourcePath}/native/lib"), file("${baseResourcePath}/nlp")
    doLast {
        def url = "https://publish.djl.ai/tokenizers"
        def files = [
                "win-x86_64/libwinpthread-1.dll" : "extra",
                "win-x86_64/libgcc_s_seh-1.dll"  : "extra",
                "win-x86_64/libstdc%2B%2B-6.dll" : "extra",
                "win-x86_64/tokenizers.dll"      : "${tokenizers_version}/jnilib/${djl_version}",
                "linux-x86_64/libtokenizers.so"  : "${tokenizers_version}/jnilib/${djl_version}",
                "linux-aarch64/libtokenizers.so" : "${tokenizers_version}/jnilib/${djl_version}",
                "osx-x86_64/libtokenizers.dylib" : "${tokenizers_version}/jnilib/${djl_version}",
                "osx-aarch64/libtokenizers.dylib": "${tokenizers_version}/jnilib/${djl_version}",
        ]
        def jnilibDir = "${project.projectDir}/jnilib/${djl_version}"
        files.each { entry ->
            def file = new File("${jnilibDir}/${URLDecoder.decode(entry.key, "UTF-8")}")
            if (file.exists()) {
                project.logger.lifecycle("prebuilt or cached file found for ${entry.key}")
            } else if ("extra" == entry.value || !project.hasProperty("jni")) {
                project.logger.lifecycle("Downloading ${url}/${entry.value}/${entry.key}")
                file.getParentFile().mkdirs()
                def downloadPath = new URL("${url}/${entry.value}/${entry.key}")
                downloadPath.withInputStream { i -> file.withOutputStream { it << i } }
            }
        }
        copy {
            from jnilibDir
            into "${baseResourcePath}/native/lib"
        }

        // write properties
        def propFile = file("${baseResourcePath}/native/lib/tokenizers.properties")
        propFile.text = "version=${tokenizers_version}-${version}\n"

        url = "https://mlrepo.djl.ai/model/nlp"
        def tasks = [
                "fill_mask",
                "question_answer",
                "text_classification",
                "text_embedding",
                "token_classification",
        ]
        def prefix = "${baseResourcePath}/nlp"
        for (String task : tasks) {
            def file = new File("${prefix}/${task}/ai.djl.huggingface.pytorch.json")
            if (file.exists()) {
                project.logger.lifecycle("PyTorch model zoo metadata alrady exists: ${task}")
            } else {
                project.logger.lifecycle("Downloading PyTorch model zoo metadata: ${task}")
                file.getParentFile().mkdirs()
                def downloadPath = new URL("${url}/${task}/ai/djl/huggingface/pytorch/models.json.gz")
                downloadPath.withInputStream { i -> file.withOutputStream { it << new GZIPInputStream(i) } }
            }

            if ("text_embedding" != task) {
                continue
            }

            file = new File("${prefix}/${task}/ai.djl.huggingface.rust.json")
            if (file.exists()) {
                project.logger.lifecycle("Rust model zoo metadata alrady exists: ${task}")
            } else {
                project.logger.lifecycle("Downloading Rust model zoo metadata: ${task}")
                file.getParentFile().mkdirs()
                def downloadPath = new URL("${url}/${task}/ai/djl/huggingface/rust/models.json.gz")
                downloadPath.withInputStream { i -> file.withOutputStream { it << new GZIPInputStream(i) } }
            }
        }
    }
}

publishing {
    publications {
        maven(MavenPublication) {
            pom {
                name = "DJL NLP utilities for Huggingface tokenizers"
                description = "Deep Java Library (DJL) NLP utilities for Huggingface tokenizers"
                url = "http://www.djl.ai/extensions/${project.name}"
            }
        }
    }
}

apply from: file("${rootProject.projectDir}/tools/gradle/cpp-formatter.gradle")

tasks.register('compileJNI') {
    doFirst {
        if (System.properties['os.name'].toLowerCase(Locale.ROOT).contains("mac")
                || System.properties['os.name'].toLowerCase(Locale.ROOT).contains("linux")) {
            def arch = System.properties["os.arch"] == "amd64" ? "x86_64" : System.properties["os.arch"]
            exec {
                commandLine "bash", "build.sh", "${tokenizers_version}", arch
            }
        } else {
            exec {
                commandLine "${project.projectDir}/build.cmd", "${tokenizers_version}"
            }
        }

        // for ci to upload to S3
        def ciDir = "${project.projectDir}/jnilib/${djl_version}/"
        copy {
            from "${project.buildDir}/jnilib"
            into ciDir
        }
        delete System.getProperty("user.home") + "/.djl.ai/tokenizers"
    }
}

tasks.register('formatPython') {
    doFirst {
        exec {
            commandLine "bash", "-c", "find . -name '*.py' -print0 | xargs -0 yapf --in-place"
        }
    }
}

clean.doFirst {
    delete System.getProperty("user.home") + "/.djl.ai/tokenizers"
    delete "rust/target"
}
